{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xLiQ3SMHYbvz",
        "outputId": "6af75678-3771-483b-f807-1a3d78939893"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Cleaned and Preprocessed Application Record:\n",
            "          ID  CNT_CHILDREN  AMT_INCOME_TOTAL  DAYS_BIRTH  DAYS_EMPLOYED  \\\n",
            "0  5008804.0     -0.589595          2.179820    0.954125      -0.469181   \n",
            "1  5008805.0     -0.589595          2.179820    0.954125      -0.469181   \n",
            "2  5008806.0     -0.589595         -0.681497   -1.308474      -0.444622   \n",
            "3  5008808.0     -0.589595          0.749162   -0.743601      -0.458436   \n",
            "4  5008809.0     -0.589595          0.749162   -0.743601      -0.458436   \n",
            "\n",
            "   FLAG_MOBIL  FLAG_WORK_PHONE  FLAG_PHONE  FLAG_EMAIL  CNT_FAM_MEMBERS  ...  \\\n",
            "0         1.0              1.0         0.0         0.0        -0.216747  ...   \n",
            "1         1.0              1.0         0.0         0.0        -0.216747  ...   \n",
            "2         1.0              0.0         0.0         0.0        -0.216747  ...   \n",
            "3         1.0              0.0         1.0         1.0        -1.331336  ...   \n",
            "4         1.0              0.0         1.0         1.0        -1.331336  ...   \n",
            "\n",
            "   OCCUPATION_TYPE_Low-skill Laborers  OCCUPATION_TYPE_Managers  \\\n",
            "0                                 0.0                       0.0   \n",
            "1                                 0.0                       0.0   \n",
            "2                                 0.0                       0.0   \n",
            "3                                 0.0                       0.0   \n",
            "4                                 0.0                       0.0   \n",
            "\n",
            "   OCCUPATION_TYPE_Medicine staff  OCCUPATION_TYPE_Private service staff  \\\n",
            "0                             0.0                                    0.0   \n",
            "1                             0.0                                    0.0   \n",
            "2                             0.0                                    0.0   \n",
            "3                             0.0                                    0.0   \n",
            "4                             0.0                                    0.0   \n",
            "\n",
            "   OCCUPATION_TYPE_Realty agents  OCCUPATION_TYPE_Sales staff  \\\n",
            "0                            0.0                          0.0   \n",
            "1                            0.0                          0.0   \n",
            "2                            0.0                          0.0   \n",
            "3                            0.0                          1.0   \n",
            "4                            0.0                          1.0   \n",
            "\n",
            "   OCCUPATION_TYPE_Secretaries  OCCUPATION_TYPE_Security staff  \\\n",
            "0                          0.0                             0.0   \n",
            "1                          0.0                             0.0   \n",
            "2                          0.0                             1.0   \n",
            "3                          0.0                             0.0   \n",
            "4                          0.0                             0.0   \n",
            "\n",
            "   OCCUPATION_TYPE_Unknown  OCCUPATION_TYPE_Waiters/barmen staff  \n",
            "0                      1.0                                   0.0  \n",
            "1                      1.0                                   0.0  \n",
            "2                      0.0                                   0.0  \n",
            "3                      0.0                                   0.0  \n",
            "4                      0.0                                   0.0  \n",
            "\n",
            "[5 rows x 56 columns]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load datasets\n",
        "application_record = pd.read_csv('application_record.csv')\n",
        "credit_record = pd.read_csv('credit_record.csv')\n",
        "\n",
        "# Step 1: Data Cleaning\n",
        "# Drop duplicates\n",
        "application_record = application_record.drop_duplicates(subset='ID')\n",
        "credit_record = credit_record.drop_duplicates(subset=['ID', 'MONTHS_BALANCE'])\n",
        "\n",
        "# Identify numeric columns\n",
        "numeric_cols = application_record.select_dtypes(include=[np.number]).columns\n",
        "\n",
        "# Handle missing values\n",
        "# Fill missing values for categorical columns with 'Unknown'\n",
        "application_record.fillna('Unknown', inplace=True)\n",
        "\n",
        "# Fill missing values for numeric columns with their median\n",
        "application_record[numeric_cols] = application_record[numeric_cols].fillna(application_record[numeric_cols].median())\n",
        "\n",
        "# Step 2: Encode Categorical Variables\n",
        "categorical_cols = [\n",
        "    'CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY',\n",
        "    'NAME_INCOME_TYPE', 'NAME_EDUCATION_TYPE',\n",
        "    'NAME_FAMILY_STATUS', 'NAME_HOUSING_TYPE', 'OCCUPATION_TYPE'\n",
        "]\n",
        "\n",
        "# Use OneHotEncoder for categorical columns\n",
        "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
        "encoded_cols = pd.DataFrame(encoder.fit_transform(application_record[categorical_cols]))\n",
        "\n",
        "# Add back encoded columns with proper names\n",
        "encoded_cols.columns = encoder.get_feature_names_out(categorical_cols)\n",
        "application_record = pd.concat([application_record, encoded_cols], axis=1)\n",
        "\n",
        "# Drop original categorical columns\n",
        "application_record.drop(columns=categorical_cols, inplace=True)\n",
        "\n",
        "# Step 3: Preprocessing Numeric Data\n",
        "numeric_cols = ['AMT_INCOME_TOTAL', 'DAYS_BIRTH', 'DAYS_EMPLOYED', 'CNT_CHILDREN', 'CNT_FAM_MEMBERS']\n",
        "\n",
        "# Normalize/Standardize the numeric columns\n",
        "scaler = StandardScaler()\n",
        "application_record[numeric_cols] = scaler.fit_transform(application_record[numeric_cols])\n",
        "\n",
        "# Display the cleaned and preprocessed data\n",
        "print(\"\\nCleaned and Preprocessed Application Record:\")\n",
        "print(application_record.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Step 1: Load the datasets\n",
        "application_record = pd.read_csv('application_record.csv')\n",
        "credit_record = pd.read_csv('credit_record.csv')\n",
        "\n",
        "# Step 2: Define the new label creation function\n",
        "def classify_clients(statuses):\n",
        "    \"\"\"\n",
        "    Classifies clients based on their worst payment status.\n",
        "    '4' or '5': Bad\n",
        "    Others: Good\n",
        "    \"\"\"\n",
        "    if any(status == '3' or status == '4' or status == '5' for status in statuses):\n",
        "        return 'Bad'\n",
        "    return 'Good'\n",
        "\n",
        "# Step 3: Label Creation\n",
        "# Group by 'ID' and apply the classify_clients function\n",
        "grouped_status = credit_record.groupby('ID')['STATUS'].apply(list)\n",
        "labels = grouped_status.apply(classify_clients).reset_index()\n",
        "labels.columns = ['ID', 'Label']\n",
        "\n",
        "# Merge the labels into credit_record\n",
        "credit_record = credit_record.merge(labels, on='ID', how='left')\n",
        "\n",
        "# Save the updated credit_record to a CSV file\n",
        "credit_record.to_csv('updated_credit_record.csv', index=False)\n",
        "\n",
        "# Optional: Save to Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "credit_record.to_csv('/content/drive/My Drive/updated_credit_record.csv', index=False)\n",
        "\n",
        "# Merge the labels with application_record\n",
        "application_record = application_record.merge(labels, on='ID', how='inner')\n",
        "\n",
        "# Step 4: Encode Categorical Variables\n",
        "categorical_cols = [\n",
        "    'CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY',\n",
        "    'NAME_INCOME_TYPE', 'NAME_EDUCATION_TYPE',\n",
        "    'NAME_FAMILY_STATUS', 'NAME_HOUSING_TYPE', 'OCCUPATION_TYPE'\n",
        "]\n",
        "\n",
        "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
        "encoded_cols = pd.DataFrame(encoder.fit_transform(application_record[categorical_cols]))\n",
        "encoded_cols.columns = encoder.get_feature_names_out(categorical_cols)\n",
        "application_record = pd.concat([application_record, encoded_cols], axis=1)\n",
        "application_record.drop(columns=categorical_cols, inplace=True)\n",
        "\n",
        "# Step 5: Preprocess Numeric Data\n",
        "numeric_cols = ['AMT_INCOME_TOTAL', 'DAYS_BIRTH', 'DAYS_EMPLOYED', 'CNT_CHILDREN', 'CNT_FAM_MEMBERS']\n",
        "scaler = StandardScaler()\n",
        "application_record[numeric_cols] = scaler.fit_transform(application_record[numeric_cols])\n",
        "\n",
        "# Step 6: Train-Test Split\n",
        "X = application_record.drop(columns=['ID', 'Label'])\n",
        "y = application_record['Label'].map({'Good': 1, 'Bad': 0})\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Step 7: Handle Class Imbalance with SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# Step 8: Train and Evaluate Models\n",
        "print(\"\\nRandom Forest Classifier\")\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "rf.fit(X_train_resampled, y_train_resampled)\n",
        "y_pred_rf = rf.predict(X_test)\n",
        "print(confusion_matrix(y_test, y_pred_rf))\n",
        "print(classification_report(y_test, y_pred_rf))\n",
        "\n",
        "print(\"\\nSupport Vector Machine\")\n",
        "svm = SVC(kernel='rbf', random_state=42)\n",
        "svm.fit(X_train_resampled, y_train_resampled)\n",
        "y_pred_svm = svm.predict(X_test)\n",
        "print(confusion_matrix(y_test, y_pred_svm))\n",
        "print(classification_report(y_test, y_pred_svm))\n",
        "\n",
        "print(\"\\nLogistic Regression\")\n",
        "logreg = LogisticRegression(max_iter=1000, random_state=42)\n",
        "logreg.fit(X_train_resampled, y_train_resampled)\n",
        "y_pred_logreg = logreg.predict(X_test)\n",
        "print(confusion_matrix(y_test, y_pred_logreg))\n",
        "print(classification_report(y_test, y_pred_logreg))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-OpVhAi4d5oE",
        "outputId": "0f6f0b39-d05c-4c61-be32-8c85698948ae"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "\n",
            "Random Forest Classifier\n",
            "[[   25    59]\n",
            " [   43 10811]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.37      0.30      0.33        84\n",
            "           1       0.99      1.00      1.00     10854\n",
            "\n",
            "    accuracy                           0.99     10938\n",
            "   macro avg       0.68      0.65      0.66     10938\n",
            "weighted avg       0.99      0.99      0.99     10938\n",
            "\n",
            "\n",
            "Support Vector Machine\n",
            "[[   32    52]\n",
            " [  754 10100]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.04      0.38      0.07        84\n",
            "           1       0.99      0.93      0.96     10854\n",
            "\n",
            "    accuracy                           0.93     10938\n",
            "   macro avg       0.52      0.66      0.52     10938\n",
            "weighted avg       0.99      0.93      0.95     10938\n",
            "\n",
            "\n",
            "Logistic Regression\n",
            "[[  49   35]\n",
            " [4160 6694]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.01      0.58      0.02        84\n",
            "           1       0.99      0.62      0.76     10854\n",
            "\n",
            "    accuracy                           0.62     10938\n",
            "   macro avg       0.50      0.60      0.39     10938\n",
            "weighted avg       0.99      0.62      0.76     10938\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J-a9kxeSevoB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importance of Label Encoding:\n",
        "\n",
        "Label Encoding is a preprocessing step used to convert categorical data into numerical values that can be understood by machine learning models. It assigns a unique integer to each category, enabling models to process categorical information.\n",
        "\n",
        "Here are the key reasons why label encoding is important:\n",
        "\n",
        "1. Compatibility with Machine Learning Models\n",
        "\n",
        "Most machine learning algorithms (e.g., Random Forest, SVM, Logistic Regression) cannot handle categorical data directly and require numerical input.\n",
        "Label encoding ensures categorical data is converted into numerical format, making it compatible with these algorithms.\n",
        "\n",
        "2. Efficiency\n",
        "\n",
        "Label encoding is computationally efficient because it simply maps each unique category to a number.\n",
        "Compared to one-hot encoding, label encoding uses less memory since it does not create multiple binary columns.\n",
        "Use Case: When the categorical variable has many unique classes, such as product IDs or user IDs.\n",
        "\n",
        "3. Preserves Ordinality\n",
        "\n",
        "If the categories have a natural order (e.g., education levels: 'High School' < 'Bachelors' < 'Masters'), label encoding preserves this order.\n",
        "This is crucial for models that can interpret ordinal relationships (e.g., tree-based models).\n",
        "\n",
        "4. Flexibility for Tree-Based Models\n",
        "\n",
        "Algorithms like Decision Trees and Random Forests can effectively handle label-encoded data without issues of numerical misinterpretation because they split data based on thresholds, not the numerical magnitude of labels.\n",
        "For example, a label-encoded [\"Cat\", \"Dog\", \"Fish\"] as [0, 1, 2] won't imply that 'Dog' (1) is midway between 'Cat' (0) and 'Fish' (2).\n",
        "\n",
        "5. Facilitates Feature Engineering\n",
        "\n",
        "Label encoding provides a simple numerical representation of categorical variables, enabling further transformations or feature engineering (e.g., scaling or interaction terms).\n",
        "\n",
        "Potential Issues:\n",
        "\n",
        "While label encoding is efficient, it has limitations:\n",
        "\n",
        "Risk of Implicit Ordinality:\n",
        "\n",
        "For non-ordinal data (e.g., [\"Cat\", \"Dog\", \"Fish\"]), models may misinterpret the numerical order as meaningful.\n",
        "In such cases, One-Hot Encoding is a better alternative.\n",
        "High Cardinality:\n",
        "\n",
        "If a categorical feature has too many unique values (e.g., [\"User1\", \"User2\", ..., \"User1000\"]), the encoded integers can lead to sparsity or inefficiency.\n",
        "\n"
      ],
      "metadata": {
        "id": "SRiLaMQE5sZP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Evaluation Report:\n",
        "\n",
        "1. Random Forest Classifier\n",
        "The model performs extremely well in identifying Good clients, achieving perfect recall and precision for Class 1.\n",
        "However, the model struggles with identifying Bad clients, as seen by the low recall (32%) and precision (48%) for Class 0.\n",
        "This suggests the model is biased towards the majority class (Good), likely due to class imbalance.\n",
        "\n",
        "2. Support Vector Machine (SVM)\n",
        "The SVM model achieves high recall (94%) and F1-score (97%) for Good clients but performs poorly for Bad clients.\n",
        "Precision for Class 0 is very low (4%), indicating many false positives.\n",
        "While overall accuracy is 93%, the poor handling of the minority class (Bad) limits its utility.\n",
        "\n",
        "3. Logistic Regression\n",
        "Logistic Regression struggles to classify Bad clients, with extremely low precision (1%) for Class 0.\n",
        "It performs better on Good clients, achieving a recall of 66% and an F1-score of 0.79.\n",
        "Overall accuracy is 65%, significantly lower than Random Forest or SVM.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "t4Unfr-W7H9f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Findings\n",
        "Class Imbalance Issue:\n",
        "\n",
        "All models struggle to identify Bad clients due to class imbalance (far more Good than Bad clients).\n",
        "This imbalance heavily influences the performance of SVM and Logistic Regression.\n",
        "Best Model:\n",
        "\n",
        "Random Forest Classifier performs the best overall, with:\n",
        "Perfect recall (1.00) for Good clients.\n",
        "Slightly better handling of Bad clients compared to SVM and Logistic Regression.\n",
        "Areas for Improvement:\n",
        "\n",
        "Class Imbalance:\n",
        "Further address imbalance with techniques like:\n",
        "Oversampling minority class (Bad) using SMOTE.\n",
        "Undersampling majority class (Good).\n",
        "Experiment with weighted loss functions.\n",
        "Feature Engineering:\n",
        "Explore additional features or transformations to improve separability of the classes.\n",
        "Conclusion\n",
        "The Random Forest Classifier is currently the best-performing model with 99% accuracy and a perfect F1-score for Good clients. However, the overall performance can be further enhanced by addressing the class imbalance issue, as even Random Forest shows bias toward the majority class."
      ],
      "metadata": {
        "id": "2L1l1XOc7ssX"
      }
    }
  ]
}